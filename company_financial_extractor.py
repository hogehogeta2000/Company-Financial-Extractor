import requests
import json
import os
import pandas as pd
from datetime import datetime, timedelta
import re
from difflib import SequenceMatcher
import time

class EDINETCompanyExtractor:
    def __init__(self, subscription_key):
        """
        EDINETä¼æ¥­ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆAPI v2å¯¾å¿œï¼‰
        """
        self.subscription_key = subscription_key
        self.base_url = "https://api.edinet-fsa.go.jp/api/v2"
        self.headers = {
            "Content-Type": "application/json"
        }
        
        # æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®è²¡å‹™æŒ‡æ¨™ãƒãƒƒãƒ”ãƒ³ã‚°
        self.target_indicators = {
            "å£²ä¸Šé«˜": ["netsales", "operatingrevenues", "revenue", "operatingincome"],
            "è³‡æœ¬é‡‘": ["capitalstock", "paidincapital", "capital"],
            "å¾“æ¥­å“¡æ•°": ["numberofemployees", "employees"]
        }
    
    def get_securities_reports_by_date_range(self, search_days=730):
        """
        æŒ‡å®šæœŸé–“ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã®ã¿ã‚’å–å¾—
        
        Args:
            search_days (int): æ¤œç´¢ã™ã‚‹éå»ã®æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ730æ—¥ï¼‰
        
        Returns:
            list: æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã®ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        """
        # ç¾åœ¨æ—¥æ™‚ã‚’å–å¾—ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºå®Ÿã«å–å¾—ã™ã‚‹ãŸã‚ï¼‰
        end_date = datetime.now()
        start_date = end_date - timedelta(days=search_days)
        
        print(f"ğŸ” æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸æ¤œç´¢æœŸé–“: {start_date.strftime('%Y-%m-%d')} ï½ {end_date.strftime('%Y-%m-%d')}")
        print(f"   æ¤œç´¢å¯¾è±¡: æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ï¼ˆdocTypeCode: 120ï¼‰ã®ã¿")
        
        securities_reports = []
        current_date = start_date
        request_count = 0
        days_with_reports = 0
        
        while current_date <= end_date:
            date_str = current_date.strftime("%Y-%m-%d")
            
            try:
                # APIåˆ¶é™å¯¾ç­–ã§å°‘ã—å¾…æ©Ÿ
                if request_count > 0 and request_count % 15 == 0:
                    print(f"  ğŸ’¤ APIåˆ¶é™å¯¾ç­–ã§3ç§’å¾…æ©Ÿ... ({request_count}æ—¥å‡¦ç†æ¸ˆã¿)")
                    time.sleep(3)
                
                documents = self._get_securities_reports_by_date(date_str)
                if documents:
                    securities_reports.extend(documents)
                    days_with_reports += 1
                    print(f"  ğŸ“… {date_str}: {len(documents)}ä»¶ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸")
                
                request_count += 1
                current_date += timedelta(days=1)
                
                # é€²æ—è¡¨ç¤ºï¼ˆé€±å˜ä½ï¼‰
                if request_count % 7 == 0:
                    progress = (request_count / search_days) * 100
                    print(f"  ğŸ“Š é€²æ—: {progress:.1f}% ({request_count}/{search_days}æ—¥)")
                
            except Exception as e:
                print(f"  âŒ {date_str} ã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                current_date += timedelta(days=1)
                continue
        
        print(f"âœ… æ¤œç´¢å®Œäº†: {days_with_reports}æ—¥é–“ã§åˆè¨ˆ {len(securities_reports)} ä»¶ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã‚’å–å¾—")
        return securities_reports
    
    def _get_securities_reports_by_date(self, date_str):
        """
        æŒ‡å®šæ—¥ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã®ã¿ã‚’å–å¾—
        """
        url = f"{self.base_url}/documents.json"
        
        params = {
            "date": date_str,
            "type": "2",  # æå‡ºæ›¸é¡ä¸€è¦§ãŠã‚ˆã³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            "Subscription-Key": self.subscription_key
        }
        
        try:
            response = requests.get(url, params=params, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            securities_reports = []
            if "results" in data and data["results"]:
                for result in data["results"]:
                    # æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ï¼ˆdocTypeCode: 120ï¼‰ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    if result.get("docTypeCode") == "120":
                        # è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰ã¾ãŸã¯EDINETã‚³ãƒ¼ãƒ‰ãŒã‚ã‚‹ä¼æ¥­ã®ã¿ï¼ˆä¸Šå ´ä¼æ¥­ç­‰ï¼‰
                        if result.get("secCode") or result.get("edinetCode"):
                            securities_reports.append(result)
                
            return securities_reports
                
        except requests.exceptions.RequestException as e:
            raise Exception(f"API request failed: {str(e)}")
    
    def find_latest_company_reports(self, company_names, securities_reports):
        """
        ä¼æ¥­åãƒªã‚¹ãƒˆã«è©²å½“ã™ã‚‹æœ€æ–°ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã‚’æ¤œç´¢
        
        Args:
            company_names (list): æ¤œç´¢ã™ã‚‹ä¼æ¥­åã®ãƒªã‚¹ãƒˆ
            securities_reports (list): æ¤œç´¢å¯¾è±¡ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            dict: ä¼æ¥­åã‚’ã‚­ãƒ¼ã¨ã—ãŸæœ€æ–°å ±å‘Šæ›¸ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
        """
        company_reports = {}
        
        print(f"\\nğŸ” {len(company_names)} ç¤¾ã®æœ€æ–°æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã‚’æ¤œç´¢ä¸­...")
        
        for company_name in company_names:
            print(f"ğŸ“Š {company_name} ã®æœ€æ–°å ±å‘Šæ›¸ã‚’æ¤œç´¢ä¸­...")
            
            company_matches = []
            
            # å…¨æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã‹ã‚‰ä¼æ¥­åã«ãƒãƒƒãƒã™ã‚‹ã‚‚ã®ã‚’æ¤œç´¢
            for report in securities_reports:
                filer_name = report.get("filerName", "")
                if not filer_name:
                    continue
                
                # é¡ä¼¼åº¦è¨ˆç®—
                score = SequenceMatcher(None, company_name.lower(), filer_name.lower()).ratio()
                
                if score >= 0.5:  # 50%ä»¥ä¸Šã®é¡ä¼¼åº¦ãŒã‚ã‚‹ã‚‚ã®
                    company_matches.append({
                        "report": report,
                        "score": score,
                        "filer_name": filer_name,
                        "submit_date": report.get("submitDateTime", "")
                    })
            
            if company_matches:
                # é¡ä¼¼åº¦é †ã§ã‚½ãƒ¼ãƒˆã€åŒã˜ä¼æ¥­ã®å ´åˆã¯æå‡ºæ—¥é †ã§ã‚½ãƒ¼ãƒˆ
                company_matches.sort(key=lambda x: (x["score"], x["submit_date"]), reverse=True)
                
                # æœ€é«˜é¡ä¼¼åº¦ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å–å¾—
                best_score = company_matches[0]["score"]
                best_matches = [m for m in company_matches if m["score"] == best_score]
                
                # åŒã˜ä¼æ¥­ã®å ´åˆã¯æœ€æ–°ã®å ±å‘Šæ›¸ã‚’é¸æŠ
                latest_match = max(best_matches, key=lambda x: x["submit_date"])
                
                company_reports[company_name] = {
                    "report": latest_match["report"],
                    "actual_name": latest_match["filer_name"],
                    "similarity": latest_match["score"],
                    "submit_date": latest_match["submit_date"],
                    "alternatives_count": len(company_matches) - 1
                }
                
                submit_date = latest_match["submit_date"][:10] if latest_match["submit_date"] else "ä¸æ˜"
                print(f"  âœ… ç™ºè¦‹: {latest_match['filer_name']}")
                print(f"     é¡ä¼¼åº¦: {latest_match['score']:.2%} | æå‡ºæ—¥: {submit_date}")
                if len(company_matches) > 1:
                    print(f"     ä»–ã« {len(company_matches)-1} ä»¶ã®å€™è£œå ±å‘Šæ›¸ãŒã‚ã‚Šã¾ã—ãŸ")
            else:
                company_reports[company_name] = {
                    "report": None,
                    "actual_name": "",
                    "similarity": 0,
                    "error": f"é¡ä¼¼åº¦50%ä»¥ä¸Šã®ä¼æ¥­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                    "alternatives_count": 0
                }
                print(f"  âŒ è¦‹ã¤ã‹ã‚‰ãš: è©²å½“ã™ã‚‹ä¼æ¥­ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        return company_reports
    
    def get_xbrl_document(self, doc_id):
        """XBRLãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—"""
        url = f"{self.base_url}/documents/{doc_id}"
        
        params = {
            "type": "5",  # CSVå½¢å¼ã®XBRLãƒ‡ãƒ¼ã‚¿
            "Subscription-Key": self.subscription_key
        }
        
        try:
            response = requests.get(url, params=params, headers=self.headers, timeout=60)
            response.raise_for_status()
            
            return {
                "success": True,
                "content": response.content
            }
            
        except requests.exceptions.RequestException as e:
            return {
                "success": False,
                "error": f"XBRLãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def extract_financial_data_from_csv(self, csv_content):
        """
        CSVã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸè²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        """
        try:
            csv_text = csv_content.decode('utf-8')
            lines = csv_text.strip().split('\\n')
            
            if len(lines) < 2:
                return {"success": False, "error": "CSVãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ã§ã™"}
            
            # CSVã‚’ãƒ‘ãƒ¼ã‚¹
            data_rows = []
            for line in lines:
                # CSVã®è¡Œã‚’é©åˆ‡ã«åˆ†å‰²ï¼ˆå¼•ç”¨ç¬¦å†…ã®ã‚«ãƒ³ãƒã‚’è€ƒæ…®ï¼‰
                row = []
                current_field = ""
                in_quotes = False
                
                for char in line:
                    if char == '"':
                        in_quotes = not in_quotes
                    elif char == ',' and not in_quotes:
                        row.append(current_field.strip('"'))
                        current_field = ""
                    else:
                        current_field += char
                
                # æœ€å¾Œã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
                row.append(current_field.strip('"'))
                
                if len(row) >= 6:
                    data_rows.append(row)
            
            if not data_rows:
                return {"success": False, "error": "æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
            
            headers = data_rows[0] if data_rows else []
            data_dict = {}
            subsidiary_info = []
            
            # å„è¡Œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            for row in data_rows[1:]:
                if len(row) >= len(headers):
                    row_dict = dict(zip(headers, row))
                    
                    element_name = row_dict.get("è¦ç´ å", "").lower()
                    context_ref = row_dict.get("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆRef", "")
                    value = row_dict.get("å€¤", "")
                    
                    # å½“æœŸã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡
                    if "prior" not in context_ref.lower() and value and value != "-":
                        
                        # å„æŒ‡æ¨™ã«ã¤ã„ã¦æ¤œç´¢
                        for indicator_name, keywords in self.target_indicators.items():
                            for keyword in keywords:
                                if keyword in element_name:
                                    # ã‚ˆã‚Šå…·ä½“çš„ãªãƒãƒƒãƒã‚’å„ªå…ˆ
                                    if indicator_name not in data_dict or len(keyword) > len(data_dict.get(f"{indicator_name}_keyword", "")):
                                        cleaned_value = self._clean_numeric_value(value)
                                        if cleaned_value is not None:
                                            data_dict[indicator_name] = cleaned_value
                                            data_dict[f"{indicator_name}_keyword"] = keyword
                                    break
                        
                        # ã‚°ãƒ«ãƒ¼ãƒ—ä¼æ¥­æƒ…å ±ã®æŠ½å‡º
                        if any(term in element_name for term in ["subsidiary", "affiliate", "é–¢ä¿‚ä¼šç¤¾", "å­ä¼šç¤¾"]):
                            if isinstance(value, str) and len(value) > 3:
                                subsidiary_info.append(value)
            
            # å†…éƒ¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±ã‚’å‰Šé™¤
            data_dict = {k: v for k, v in data_dict.items() if not k.endswith('_keyword')}
            
            # ã‚°ãƒ«ãƒ¼ãƒ—ä¼æ¥­æƒ…å ±ã‚’ã¾ã¨ã‚ã‚‹
            if subsidiary_info:
                data_dict["é–¢é€£ä¼æ¥­æƒ…å ±"] = "; ".join(set(subsidiary_info[:5]))
            
            return {
                "success": True,
                "data": data_dict
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def _clean_numeric_value(self, value_str):
        """æ•°å€¤æ–‡å­—åˆ—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # ã‚«ãƒ³ãƒã‚„å††ãƒãƒ¼ã‚¯ã‚’é™¤å»
            cleaned = re.sub(r'[,Â¥å††]', '', str(value_str))
            # æ•°å€¤ä»¥å¤–ã®æ–‡å­—ã‚’é™¤å»ï¼ˆãƒã‚¤ãƒŠã‚¹è¨˜å·ã¨å°æ•°ç‚¹ã¯ä¿æŒï¼‰
            cleaned = re.sub(r'[^\\d.-]', '', cleaned)
            
            if cleaned and cleaned != '-':
                return float(cleaned)
            return None
        except:
            return None
    
    def extract_companies_data(self, company_names, search_days=730):
        """
        è¤‡æ•°ä¼æ¥­åã®æœ€æ–°æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Args:
            company_names (list): ä¼æ¥­åã®ãƒªã‚¹ãƒˆ
            search_days (int): æ¤œç´¢ã™ã‚‹éå»ã®æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ730æ—¥ï¼‰
        
        Returns:
            pd.DataFrame: æŠ½å‡ºçµæœã®DataFrame
        """
        print(f"=== EDINET æœ€æ–°æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ãƒ‡ãƒ¼ã‚¿æŠ½å‡º ===")
        print(f"å¯¾è±¡ä¼æ¥­æ•°: {len(company_names)}")
        print(f"æ¤œç´¢æœŸé–“: éå»{search_days}æ—¥ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã¾ã§ï¼‰")
        print("=" * 60)
        
        # 1. æŒ‡å®šæœŸé–“ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã®ã¿ã‚’å–å¾—
        securities_reports = self.get_securities_reports_by_date_range(search_days)
        
        if not securities_reports:
            print("âŒ æœŸé–“å†…ã«æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return pd.DataFrame()
        
        # 2. ä¼æ¥­åã§æœ€æ–°ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã‚’æ¤œç´¢
        company_reports = self.find_latest_company_reports(company_names, securities_reports)
        
        # 3. å„ä¼æ¥­ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        results = []
        
        print(f"\\n=== è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå‡¦ç† ===")
        
        for i, company_name in enumerate(company_names, 1):
            print(f"\\n[{i}/{len(company_names)}] {company_name} ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­...")
            
            company_info = company_reports.get(company_name)
            
            if not company_info or not company_info.get("report"):
                error_msg = company_info.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼") if company_info else "ä¼æ¥­æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {error_msg}")
                results.append({
                    "ä¼æ¥­å": company_name,
                    "docID": None,
                    "docDescription": None,
                    "æå‡ºæ—¥": None,
                    "å£²ä¸Šé«˜": None,
                    "è³‡æœ¬é‡‘": None,
                    "å¾“æ¥­å“¡æ•°": None,
                    "ã‚¨ãƒ©ãƒ¼": error_msg
                })
                continue
            
            report = company_info["report"]
            actual_name = company_info["actual_name"]
            doc_id = report.get("docID")
            doc_description = report.get("docDescription", "")
            submit_date = report.get("submitDateTime", "")[:10] if report.get("submitDateTime") else ""
            
            print(f"  ğŸ“Š ä¼æ¥­å: {actual_name}")
            print(f"  ğŸ“„ å ±å‘Šæ›¸: {doc_description}")
            print(f"  ğŸ“… æå‡ºæ—¥: {submit_date}")
            print(f"  ğŸ†” docID: {doc_id}")
            
            # XBRLãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            print(f"  ğŸ”„ XBRLãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            xbrl_result = self.get_xbrl_document(doc_id)
            
            if not xbrl_result["success"]:
                print(f"  âŒ XBRLãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {xbrl_result['error']}")
                results.append({
                    "ä¼æ¥­å": actual_name,
                    "docID": doc_id,
                    "docDescription": doc_description,
                    "æå‡ºæ—¥": submit_date,
                    "å£²ä¸Šé«˜": None,
                    "è³‡æœ¬é‡‘": None,
                    "å¾“æ¥­å“¡æ•°": None,
                    "ã‚¨ãƒ©ãƒ¼": xbrl_result["error"]
                })
                continue
            
            # è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            print(f"  ğŸ”„ è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...")
            financial_result = self.extract_financial_data_from_csv(xbrl_result["content"])
            
            if not financial_result["success"]:
                print(f"  âŒ è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {financial_result['error']}")
                results.append({
                    "ä¼æ¥­å": actual_name,
                    "docID": doc_id,
                    "docDescription": doc_description,
                    "æå‡ºæ—¥": submit_date,
                    "å£²ä¸Šé«˜": None,
                    "è³‡æœ¬é‡‘": None,
                    "å¾“æ¥­å“¡æ•°": None,
                    "ã‚¨ãƒ©ãƒ¼": financial_result["error"]
                })
                continue
            
            # çµæœã‚’ã¾ã¨ã‚ã‚‹
            financial_data = financial_result["data"]
            
            company_data = {
                "ä¼æ¥­å": actual_name,
                "docID": doc_id,
                "docDescription": doc_description,
                "æå‡ºæ—¥": submit_date,
                "å£²ä¸Šé«˜": financial_data.get("å£²ä¸Šé«˜"),
                "è³‡æœ¬é‡‘": financial_data.get("è³‡æœ¬é‡‘"),
                "å¾“æ¥­å“¡æ•°": financial_data.get("å¾“æ¥­å“¡æ•°"),
            }
            
            # é–¢é€£ä¼æ¥­æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if "é–¢é€£ä¼æ¥­æƒ…å ±" in financial_data:
                company_data["é–¢é€£ä¼æ¥­æƒ…å ±"] = financial_data["é–¢é€£ä¼æ¥­æƒ…å ±"]
            
            results.append(company_data)
            
            # æŠ½å‡ºæˆåŠŸã®æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            extracted_count = sum(1 for v in [
                financial_data.get("å£²ä¸Šé«˜"), 
                financial_data.get("è³‡æœ¬é‡‘"), 
                financial_data.get("å¾“æ¥­å“¡æ•°")
            ] if v is not None)
            
            print(f"  âœ… å®Œäº†: {extracted_count}/3 å€‹ã®è²¡å‹™æŒ‡æ¨™ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
            
            # è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦è¡¨ç¤º
            if financial_data.get("å£²ä¸Šé«˜"):
                print(f"     ğŸ’° å£²ä¸Šé«˜: {financial_data.get('å£²ä¸Šé«˜'):,.0f}å††")
            if financial_data.get("è³‡æœ¬é‡‘"):
                print(f"     ğŸ¦ è³‡æœ¬é‡‘: {financial_data.get('è³‡æœ¬é‡‘'):,.0f}å††")
            if financial_data.get("å¾“æ¥­å“¡æ•°"):
                print(f"     ğŸ‘¥ å¾“æ¥­å“¡æ•°: {financial_data.get('å¾“æ¥­å“¡æ•°'):,.0f}äºº")
        
        # DataFrameã«å¤‰æ›
        df = pd.DataFrame(results)
        return df

def main():
    # APIã‚­ãƒ¼ã‚’è¨­å®š
    api_key = os.getenv("EDINET_API_KEY")
    
    if not api_key:
        print("ERROR: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("ç’°å¢ƒå¤‰æ•° EDINET_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    extractor = EDINETCompanyExtractor(api_key)
    
    # å¯¾è±¡ä¼æ¥­åãƒªã‚¹ãƒˆ
    company_names = [
        "NTTãƒ‡ãƒ¼ã‚¿",
        "å¯Œå£«é€š",
        "é‡æ‘ç·åˆç ”ç©¶æ‰€",
        "æ—¥æœ¬é›»ä¿¡é›»è©±",
        "TIS"
    ]
    
    print("=== EDINET API v2 - æœ€æ–°æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸æŠ½å‡ºãƒ„ãƒ¼ãƒ« ===\\n")
    
    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå®Ÿè¡Œï¼ˆéå»730æ—¥ã‚’æ¤œç´¢ã—ã¦æœ€æ–°ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã‚’ç¢ºå®Ÿã«å–å¾—ï¼‰
    results_df = extractor.extract_companies_data(company_names, search_days=730)
    
    if results_df.empty:
        print("\\nâŒ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    print(f"\\n{'='*80}")
    print(f"=== æœ€çµ‚æŠ½å‡ºçµæœ ===")
    print(f"{'='*80}")
    
    # çµæœã‚’è¦‹ã‚„ã™ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¦è¡¨ç¤º
    display_df = results_df.copy()
    
    # æ•°å€¤ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    for col in ['å£²ä¸Šé«˜', 'è³‡æœ¬é‡‘']:
        if col in display_df.columns:
            display_df[col] = display_df[col].apply(
                lambda x: f"{x:,.0f}å††" if pd.notnull(x) and x != 0 else "ãƒ‡ãƒ¼ã‚¿ãªã—"
            )
    
    if 'å¾“æ¥­å“¡æ•°' in display_df.columns:
        display_df['å¾“æ¥­å“¡æ•°'] = display_df['å¾“æ¥­å“¡æ•°'].apply(
            lambda x: f"{x:,.0f}äºº" if pd.notnull(x) and x != 0 else "ãƒ‡ãƒ¼ã‚¿ãªã—"
        )
    
    print(display_df.to_string(index=False))
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # CSVä¿å­˜ï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
    csv_filename = f"latest_securities_reports_{timestamp}.csv"
    results_df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
    print(f"\\nğŸ“ ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜: {csv_filename}")
    
    # Excelä¿å­˜ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ï¼‰
    excel_filename = f"latest_securities_reports_{timestamp}.xlsx"
    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
        # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆ
        results_df.to_excel(writer, sheet_name='ç”Ÿãƒ‡ãƒ¼ã‚¿', index=False)
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã‚·ãƒ¼ãƒˆ
        display_df.to_excel(writer, sheet_name='ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿', index=False)
    
    print(f"ğŸ“ çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜: {excel_filename}")
    print(f"   - 'ç”Ÿãƒ‡ãƒ¼ã‚¿'ã‚·ãƒ¼ãƒˆ: å…ƒã®æ•°å€¤ãƒ‡ãƒ¼ã‚¿")
    print(f"   - 'ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿'ã‚·ãƒ¼ãƒˆ: è¦‹ã‚„ã™ãæ•´å½¢ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿")
    
    # çµ±è¨ˆæƒ…å ±ã®è©³ç´°è¡¨ç¤º
    success_count = len(results_df[results_df["ã‚¨ãƒ©ãƒ¼"].isna()]) if "ã‚¨ãƒ©ãƒ¼" in results_df.columns else len(results_df)
    
    print(f"\\nğŸ“Š æŠ½å‡ºçµ±è¨ˆ:")
    print(f"   ğŸ“ˆ å‡¦ç†ä¼æ¥­æ•°: {len(results_df)} ç¤¾")
    print(f"   âœ… æˆåŠŸä¼æ¥­æ•°: {success_count} ç¤¾")
    print(f"   ğŸ“Š æˆåŠŸç‡: {success_count/len(results_df):.1%}")
    
    # æˆåŠŸã—ãŸä¼æ¥­ã®è©³ç´°
    if success_count > 0:
        successful_companies = results_df[results_df["ã‚¨ãƒ©ãƒ¼"].isna()] if "ã‚¨ãƒ©ãƒ¼" in results_df.columns else results_df
        print(f"\\nâœ… æˆåŠŸã—ãŸä¼æ¥­:")
        for _, row in successful_companies.iterrows():
            submit_date = row['æå‡ºæ—¥'] if 'æå‡ºæ—¥' in row else 'N/A'
            print(f"   â€¢ {row['ä¼æ¥­å']} (æå‡ºæ—¥: {submit_date})")
    
    # å¤±æ•—ã—ãŸä¼æ¥­ã®è©³ç´°
    if success_count < len(results_df):
        failed_companies = results_df[results_df["ã‚¨ãƒ©ãƒ¼"].notna()] if "ã‚¨ãƒ©ãƒ¼" in results_df.columns else pd.DataFrame()
        if not failed_companies.empty:
            print(f"\\nâŒ å¤±æ•—ã—ãŸä¼æ¥­:")
            for _, row in failed_companies.iterrows():
                print(f"   â€¢ {row['ä¼æ¥­å']}: {row['ã‚¨ãƒ©ãƒ¼']}")

if __name__ == "__main__":
    main()
