import requests
import json
import os
import pandas as pd
from datetime import datetime, timedelta
import re
from difflib import SequenceMatcher

class EDINETCompanyNameExtractor:
    def __init__(self, subscription_key):
        """
        EDINETä¼æ¥­åæ¤œç´¢ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        """
        self.subscription_key = subscription_key
        self.base_url = "https://api.edinet-fsa.go.jp/api/v2"
        self.headers = {
            "Ocp-Apim-Subscription-Key": subscription_key,
            "Content-Type": "application/json"
        }
        
        # æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®è²¡å‹™æŒ‡æ¨™ãƒãƒƒãƒ”ãƒ³ã‚°
        self.target_indicators = {
            "å£²ä¸Šé«˜": ["netsales", "operatingrevenues", "revenue", "ordingyrevenues"],
            "è³‡æœ¬é‡‘": ["capitalstock", "paidincapital", "capital"],
            "å¾“æ¥­å“¡æ•°": ["numberofemployees", "employees"]
        }
    
    def search_company_by_name(self, company_name):
        """
        ä¼æ¥­åã§ä¼æ¥­ã‚’æ¤œç´¢ã—ã€æœ€ã‚‚é©åˆã™ã‚‹ä¼æ¥­ã‚’è¿”ã™
        
        Args:
            company_name (str): æ¤œç´¢ã™ã‚‹ä¼æ¥­å
            
        Returns:
            dict: æ¤œç´¢çµæœ
        """
        url = f"{self.base_url}/documents.json"
        
        # éå»2å¹´é–“ã‚’æ¤œç´¢ç¯„å›²ã¨ã™ã‚‹
        end_date = datetime.now().strftime("%Y-%m-%d")
        
        params = {
            "date": end_date,
            "type": "1",  # ä¼æ¥­åã§ã®æ¤œç´¢
            "code": company_name,  # ä¼æ¥­åã‚’æŒ‡å®š
            "Subscription-Key": self.subscription_key
        }
        
        try:
            response = requests.get(url, params=params, headers=self.headers)
            response.raise_for_status()
            
            data = response.json()
            
            if "results" not in data or not data["results"]:
                return {
                    "success": False,
                    "error": f"ä¼æ¥­å '{company_name}' ã«è©²å½“ã™ã‚‹ä¼æ¥­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                }
            
            # ä¼æ¥­åã®é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆã—ã¦æœ€é©ãªä¼æ¥­ã‚’é¸æŠ
            best_match = None
            best_score = 0
            
            for result in data["results"]:
                filer_name = result.get("filerName", "")
                # é¡ä¼¼åº¦ã‚’è¨ˆç®—
                score = SequenceMatcher(None, company_name, filer_name).ratio()
                
                if score > best_score:
                    best_score = score
                    best_match = result
            
            # é¡ä¼¼åº¦ãŒ50%æœªæº€ã®å ´åˆã¯ãƒãƒƒãƒå¤±æ•—ã¨ã™ã‚‹
            if best_score < 0.5:
                return {
                    "success": False,
                    "error": f"ä¼æ¥­å '{company_name}' ã«ååˆ†ã«é¡ä¼¼ã™ã‚‹ä¼æ¥­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆæœ€é«˜é¡ä¼¼åº¦: {best_score:.2%}ï¼‰"
                }
            
            return {
                "success": True,
                "company_info": best_match,
                "similarity_score": best_score
            }
            
        except requests.exceptions.RequestException as e:
            return {
                "success": False,
                "error": f"ä¼æ¥­æ¤œç´¢APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def search_latest_securities_report(self, edin_code):
        """
        EDINã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦æœ€æ–°ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã‚’æ¤œç´¢
        
        Args:
            edin_code (str): EDINã‚³ãƒ¼ãƒ‰
            
        Returns:
            dict: æ¤œç´¢çµæœ
        """
        url = f"{self.base_url}/documents.json"
        
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=730)).strftime("%Y-%m-%d")
        
        params = {
            "date": end_date,
            "type": "2",  # EDINã‚³ãƒ¼ãƒ‰ã§ã®æ¤œç´¢
            "code": edin_code,
            "Subscription-Key": self.subscription_key
        }
        
        try:
            response = requests.get(url, params=params, headers=self.headers)
            response.raise_for_status()
            
            data = response.json()
            
            # æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ï¼ˆ120ï¼‰ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            securities_reports = []
            if "results" in data:
                for result in data["results"]:
                    if "120" in result.get("ordinanceCode", ""):
                        securities_reports.append(result)
            
            if securities_reports:
                # æå‡ºæ—¥ã§ã‚½ãƒ¼ãƒˆã—ã¦æœ€æ–°ã®ã‚‚ã®ã‚’è¿”ã™
                securities_reports.sort(key=lambda x: x.get("submitDateTime", ""), reverse=True)
                return {
                    "success": True,
                    "document": securities_reports[0]
                }
            else:
                return {
                    "success": False,
                    "error": "æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                }
                
        except requests.exceptions.RequestException as e:
            return {
                "success": False,
                "error": f"æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def get_xbrl_document(self, doc_id):
        """XBRLãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—"""
        url = f"{self.base_url}/documents/{doc_id}"
        
        params = {
            "type": "5",  # CSVå½¢å¼ã®XBRLãƒ‡ãƒ¼ã‚¿
            "Subscription-Key": self.subscription_key
        }
        
        try:
            response = requests.get(url, params=params, headers=self.headers)
            response.raise_for_status()
            
            return {
                "success": True,
                "content": response.content
            }
            
        except requests.exceptions.RequestException as e:
            return {
                "success": False,
                "error": f"XBRLãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def extract_financial_data_from_csv(self, csv_content):
        """
        CSVã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸè²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        """
        try:
            csv_text = csv_content.decode('utf-8')
            lines = csv_text.strip().split('\n')
            
            if len(lines) < 2:
                return {"success": False, "error": "CSVãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ã§ã™"}
            
            # CSVã‚’ãƒ‘ãƒ¼ã‚¹
            data_rows = []
            for line in lines:
                row = [item.strip('"') for item in line.split('","')]
                if len(row) >= 6:
                    data_rows.append(row)
            
            if not data_rows:
                return {"success": False, "error": "æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
            
            headers = data_rows[0] if data_rows else []
            data_dict = {}
            subsidiary_info = []
            
            # å„è¡Œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            for row in data_rows[1:]:
                if len(row) >= len(headers):
                    row_dict = dict(zip(headers, row))
                    
                    element_name = row_dict.get("è¦ç´ å", "").lower()
                    context_ref = row_dict.get("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆRef", "")
                    value = row_dict.get("å€¤", "")
                    
                    # å½“æœŸã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡
                    if "prior" not in context_ref.lower() and value and value != "-":
                        
                        # å„æŒ‡æ¨™ã«ã¤ã„ã¦æ¤œç´¢
                        for indicator_name, keywords in self.target_indicators.items():
                            for keyword in keywords:
                                if keyword in element_name:
                                    # ã‚ˆã‚Šå…·ä½“çš„ãªãƒãƒƒãƒã‚’å„ªå…ˆ
                                    if indicator_name not in data_dict or len(keyword) > len(data_dict.get(f"{indicator_name}_keyword", "")):
                                        cleaned_value = self._clean_numeric_value(value)
                                        if cleaned_value is not None:
                                            data_dict[indicator_name] = cleaned_value
                                            data_dict[f"{indicator_name}_keyword"] = keyword
                                    break
                        
                        # ã‚°ãƒ«ãƒ¼ãƒ—ä¼æ¥­æƒ…å ±ã®æŠ½å‡º
                        if any(term in element_name for term in ["subsidiary", "affiliate", "é–¢ä¿‚ä¼šç¤¾", "å­ä¼šç¤¾"]):
                            if isinstance(value, str) and len(value) > 3:  # æ„å‘³ã®ã‚ã‚‹æ–‡å­—åˆ—ã®ã¿
                                subsidiary_info.append(value)
            
            # å†…éƒ¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±ã‚’å‰Šé™¤
            data_dict = {k: v for k, v in data_dict.items() if not k.endswith('_keyword')}
            
            # ã‚°ãƒ«ãƒ¼ãƒ—ä¼æ¥­æƒ…å ±ã‚’ã¾ã¨ã‚ã‚‹
            if subsidiary_info:
                data_dict["é–¢é€£ä¼æ¥­æƒ…å ±"] = "; ".join(set(subsidiary_info[:5]))  # é‡è¤‡é™¤å»ã—ã¦æœ€å¤§5ä»¶
            
            return {
                "success": True,
                "data": data_dict
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def _clean_numeric_value(self, value_str):
        """æ•°å€¤æ–‡å­—åˆ—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # ã‚«ãƒ³ãƒã‚„å††ãƒãƒ¼ã‚¯ã‚’é™¤å»
            cleaned = re.sub(r'[,Â¥å††]', '', str(value_str))
            # æ•°å€¤ä»¥å¤–ã®æ–‡å­—ã‚’é™¤å»ï¼ˆãƒã‚¤ãƒŠã‚¹è¨˜å·ã¨å°æ•°ç‚¹ã¯ä¿æŒï¼‰
            cleaned = re.sub(r'[^\d.-]', '', cleaned)
            
            if cleaned and cleaned != '-':
                return float(cleaned)
            return None
        except:
            return None
    
    def extract_companies_data(self, company_names):
        """
        è¤‡æ•°ä¼æ¥­åã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Args:
            company_names (list): ä¼æ¥­åã®ãƒªã‚¹ãƒˆ
            
        Returns:
            pd.DataFrame: æŠ½å‡ºçµæœã®DataFrame
        """
        results = []
        
        print(f"å¯¾è±¡ä¼æ¥­æ•°: {len(company_names)}")
        print("=" * 60)
        
        for i, company_name in enumerate(company_names, 1):
            print(f"[{i}/{len(company_names)}] å‡¦ç†ä¸­: {company_name}")
            
            # 1. ä¼æ¥­åã§ä¼æ¥­ã‚’æ¤œç´¢
            search_result = self.search_company_by_name(company_name)
            
            if not search_result["success"]:
                print(f"  âŒ ä¼æ¥­æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {search_result['error']}")
                results.append({
                    "ä¼æ¥­å": company_name,
                    "docID": None,
                    "docDescription": None,
                    "å£²ä¸Šé«˜": None,
                    "è³‡æœ¬é‡‘": None,
                    "å¾“æ¥­å“¡æ•°": None,
                    "ã‚¨ãƒ©ãƒ¼": search_result["error"]
                })
                continue
            
            company_info = search_result["company_info"]
            edin_code = company_info.get("edinetCode")
            actual_company_name = company_info.get("filerName", company_name)
            similarity = search_result["similarity_score"]
            
            print(f"  ğŸ” ãƒãƒƒãƒã—ãŸä¼æ¥­: {actual_company_name} (é¡ä¼¼åº¦: {similarity:.2%})")
            
            # 2. æœ€æ–°ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã‚’æ¤œç´¢
            report_result = self.search_latest_securities_report(edin_code)
            
            if not report_result["success"]:
                print(f"  âŒ æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {report_result['error']}")
                results.append({
                    "ä¼æ¥­å": actual_company_name,
                    "docID": None,
                    "docDescription": None,
                    "å£²ä¸Šé«˜": None,
                    "è³‡æœ¬é‡‘": None,
                    "å¾“æ¥­å“¡æ•°": None,
                    "ã‚¨ãƒ©ãƒ¼": report_result["error"]
                })
                continue
            
            doc = report_result["document"]
            doc_id = doc.get("docID")
            doc_description = doc.get("docDescription", "")
            
            print(f"  ğŸ“„ å ±å‘Šæ›¸: {doc_description}")
            
            # 3. XBRLãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            xbrl_result = self.get_xbrl_document(doc_id)
            
            if not xbrl_result["success"]:
                print(f"  âŒ XBRLãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {xbrl_result['error']}")
                results.append({
                    "ä¼æ¥­å": actual_company_name,
                    "docID": doc_id,
                    "docDescription": doc_description,
                    "å£²ä¸Šé«˜": None,
                    "è³‡æœ¬é‡‘": None,
                    "å¾“æ¥­å“¡æ•°": None,
                    "ã‚¨ãƒ©ãƒ¼": xbrl_result["error"]
                })
                continue
            
            # 4. è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            financial_result = self.extract_financial_data_from_csv(xbrl_result["content"])
            
            if not financial_result["success"]:
                print(f"  âŒ è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {financial_result['error']}")
                results.append({
                    "ä¼æ¥­å": actual_company_name,
                    "docID": doc_id,
                    "docDescription": doc_description,
                    "å£²ä¸Šé«˜": None,
                    "è³‡æœ¬é‡‘": None,
                    "å¾“æ¥­å“¡æ•°": None,
                    "ã‚¨ãƒ©ãƒ¼": financial_result["error"]
                })
                continue
            
            # 5. çµæœã‚’ã¾ã¨ã‚ã‚‹
            financial_data = financial_result["data"]
            
            company_data = {
                "ä¼æ¥­å": actual_company_name,
                "docID": doc_id,
                "docDescription": doc_description,
                "å£²ä¸Šé«˜": financial_data.get("å£²ä¸Šé«˜"),
                "è³‡æœ¬é‡‘": financial_data.get("è³‡æœ¬é‡‘"),
                "å¾“æ¥­å“¡æ•°": financial_data.get("å¾“æ¥­å“¡æ•°"),
            }
            
            # é–¢é€£ä¼æ¥­æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if "é–¢é€£ä¼æ¥­æƒ…å ±" in financial_data:
                company_data["é–¢é€£ä¼æ¥­æƒ…å ±"] = financial_data["é–¢é€£ä¼æ¥­æƒ…å ±"]
            
            results.append(company_data)
            
            extracted_count = sum(1 for v in [financial_data.get("å£²ä¸Šé«˜"), financial_data.get("è³‡æœ¬é‡‘"), financial_data.get("å¾“æ¥­å“¡æ•°")] if v is not None)
            print(f"  âœ… å®Œäº†: {extracted_count}/3 å€‹ã®æŒ‡æ¨™ã‚’æŠ½å‡º")
        
        # DataFrameã«å¤‰æ›
        df = pd.DataFrame(results)
        return df
    
    def validate_company_names(self, company_names):
        """
        ä¼æ¥­åãƒªã‚¹ãƒˆã®äº‹å‰æ¤œè¨¼
        
        Args:
            company_names (list): ä¼æ¥­åã®ãƒªã‚¹ãƒˆ
            
        Returns:
            dict: æ¤œè¨¼çµæœ
        """
        print("=== ä¼æ¥­åã®äº‹å‰æ¤œè¨¼ ===")
        
        validation_results = []
        valid_companies = []
        invalid_companies = []
        
        for company_name in company_names:
            search_result = self.search_company_by_name(company_name)
            
            if search_result["success"]:
                actual_name = search_result["company_info"].get("filerName", "")
                similarity = search_result["similarity_score"]
                
                validation_results.append({
                    "å…¥åŠ›ä¼æ¥­å": company_name,
                    "ãƒãƒƒãƒã—ãŸä¼æ¥­å": actual_name,
                    "é¡ä¼¼åº¦": f"{similarity:.2%}",
                    "status": "âœ… ãƒãƒƒãƒ"
                })
                valid_companies.append(company_name)
                print(f"âœ… {company_name} â†’ {actual_name} (é¡ä¼¼åº¦: {similarity:.2%})")
            else:
                validation_results.append({
                    "å…¥åŠ›ä¼æ¥­å": company_name,
                    "ãƒãƒƒãƒã—ãŸä¼æ¥­å": "",
                    "é¡ä¼¼åº¦": "",
                    "status": f"âŒ {search_result['error']}"
                })
                invalid_companies.append(company_name)
                print(f"âŒ {company_name}: {search_result['error']}")
        
        return {
            "validation_df": pd.DataFrame(validation_results),
            "valid_companies": valid_companies,
            "invalid_companies": invalid_companies,
            "success_rate": len(valid_companies) / len(company_names) if company_names else 0
        }

def main():
    # APIã‚­ãƒ¼ã‚’è¨­å®š
    api_key = os.getenv("EDINET_API_KEY")
    
    if not api_key:
        print("ERROR: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("ç’°å¢ƒå¤‰æ•° EDINET_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    extractor = EDINETCompanyNameExtractor(api_key)
    
    # å¯¾è±¡ä¼æ¥­åãƒªã‚¹ãƒˆï¼ˆä¾‹ï¼‰
    company_names = [
        "NTTãƒ‡ãƒ¼ã‚¿",
        "å¯Œå£«é€š",
        "é‡æ‘ç·åˆç ”ç©¶æ‰€",
        "æ—¥æœ¬é›»ä¿¡é›»è©±",
        "TIS"
    ]
    
    print("=== EDINET ä¼æ¥­åæ¤œç´¢ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡º ===\n")
    
    # 1. ä¼æ¥­åã®äº‹å‰æ¤œè¨¼
    validation_result = extractor.validate_company_names(company_names)
    
    print(f"\nä¼æ¥­åæ¤œè¨¼çµæœ:")
    print(validation_result["validation_df"].to_string(index=False))
    print(f"\næˆåŠŸç‡: {validation_result['success_rate']:.1%} ({len(validation_result['valid_companies'])}/{len(company_names)})")
    
    if validation_result["invalid_companies"]:
        print(f"\nâš ï¸  ä»¥ä¸‹ã®ä¼æ¥­åã¯å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™:")
        for invalid_name in validation_result["invalid_companies"]:
            print(f"   - {invalid_name}")
    
    # 2. æœ‰åŠ¹ãªä¼æ¥­ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    if validation_result["valid_companies"]:
        print(f"\n=== è²¡å‹™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºé–‹å§‹ ===")
        
        results_df = extractor.extract_companies_data(validation_result["valid_companies"])
        
        print(f"\n=== æŠ½å‡ºçµæœ ===")
        print(results_df.to_string(index=False))
        
        # 3. ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # CSVä¿å­˜
        csv_filename = f"company_financial_data_{timestamp}.csv"
        results_df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"\nğŸ“ çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜: {csv_filename}")
        
        # Excelä¿å­˜
        excel_filename = f"company_financial_data_{timestamp}.xlsx"
        with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
            results_df.to_excel(writer, sheet_name='è²¡å‹™ãƒ‡ãƒ¼ã‚¿', index=False)
            validation_result["validation_df"].to_excel(writer, sheet_name='ä¼æ¥­åæ¤œè¨¼', index=False)
        
        print(f"ğŸ“ çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜: {excel_filename}")
        
        # 4. çµ±è¨ˆæƒ…å ±
        success_count = len(results_df[results_df["ã‚¨ãƒ©ãƒ¼"].isna()]) if "ã‚¨ãƒ©ãƒ¼" in results_df.columns else len(results_df)
        print(f"\nğŸ“Š çµ±è¨ˆæƒ…å ±:")
        print(f"   å‡¦ç†ä¼æ¥­æ•°: {len(results_df)}")
        print(f"   æˆåŠŸä¼æ¥­æ•°: {success_count}")
        print(f"   æˆåŠŸç‡: {success_count/len(results_df):.1%}")
    
    else:
        print("\nâŒ æœ‰åŠ¹ãªä¼æ¥­åãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")

if __name__ == "__main__":
    main()
